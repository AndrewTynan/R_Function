https://dranolia.medium.com/python-cheatsheet-51b552b56a81
https://www.markhneedham.com/blog/2021/04/11/pandas-format-dataframe-numbers-commas-decimals/
https://pbpython.com/groupby-agg.html 
https://github.com/pandas-dev/pandas/issues/25072
https://python.plainenglish.io/5-python-libraries-every-data-scientist-should-know-about-ce04bf19d58d
https://towardsdatascience.com/the-unreasonable-effectiveness-of-method-chaining-in-pandas-15c2109e3c69
https://ponder.io/professional-pandas-the-pandas-assign-method-and-chaining/ 
https://pbpython.com/styling-pandas.html
https://gist.github.com/Abdelkrim/02e604fc38e7f35969e5552f13e4af0a
https://medium.com/@ThomTechSavvy/data-analysis-with-a-single-line-of-code-using-advanced-python-libraries-automate-your-eda-and-e1e3fb2ed110
https://medium.com/@roelljr/ultimate-python-cheat-sheet-practical-python-for-everyday-tasks-c267c1394ee8
https://stackoverflow.com/questions/579310/formatting-long-numbers-as-strings
https://github.com/groundhogday321/python-plotnine/blob/main/python%20plotnine%20ggplot2.ipynb
https://blog.devops.dev/top-10-advanced-sql-queries-dd5717b7e902


https://pingouin-stats.org/build/html/generated/pingouin.anova.html
https://www.statsmodels.org/devel/examples/notebooks/generated/interactions_anova.html
https://mattchoward.com/two-way-anova-in-python/
https://www.statology.org/two-way-anova-python/
http://www.sthda.com/english/wiki/two-way-anova-test-in-r
https://www.geeksforgeeks.org/how-to-perform-a-two-way-anova-in-python/

https://pingouin-stats.org/build/html/generated/pingouin.ttest.html

CUPED (Controlled-experiment Using Pre-Experiment Data).
https://www.statsig.com/blog/cuped
https://www.datasciencecentral.com/cuped-for-starters-enhancing-controlled-experiments-with-pre-experiment-data/#:~:text=What%20is%20CUPED%20and%20how,not%20change%20while%20variance%20decreases.


https://cran.r-project.org/web/packages/infer/vignettes/t_test.html
https://www.itl.nist.gov/div898/handbook/prc/section2/prc221.htm#:~:text=Tests%20of%20hypotheses%20that%20can,on%20the%20question%20at%20hand.
https://statisticsbyjim.com/hypothesis-testing/comparing-hypothesis-tests-data-types/


https://geoffruddock.com/run-ab-test-with-unequal-sample-size/
https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/
https://dominicsando.medium.com/why-two-sided-testing-is-reducing-your-a-b-testing-programs-impact-by-25-11d72276446a
https://www.theanalysisfactor.com/when-unequal-sample-sizes-are-and-are-not-a-problem-in-anova/ 
https://www.editage.com/insights/4-ways-to-make-the-most-of-your-anova-uncovering-the-real-differences-between-groups
https://stats.stackexchange.com/questions/501126/does-two-way-anova-still-works-fine-with-unequal-sample-sizes
https://online.stat.psu.edu/stat509/lesson/9/9.5

https://statisticaloddsandends.wordpress.com/2022/05/20/t-learners-s-learners-and-x-learners/
https://www.inference.vc/causal-inference-3-counterfactuals/
https://www.statisticsteacher.org/2017/09/15/what-is-power/ 
https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia

 john.backusmayes@gmail.com

https://en.wikipedia.org/wiki/Uplift_modelling#:~:text=Uplift%20modelling%2C%20also%20known%20as,action)%20on%20an%20individual's%20behaviour.
https://nbviewer.org/github/maks-sh/scikit-uplift/blob/master/notebooks/RetailHero_EN.ipynb
https://www.uber.com/blog/causal-inference-at-uber/
https://causalml.readthedocs.io/en/latest/about.html#intro-to-causal-machine-learning
https://causalml.readthedocs.io/en/latest/
https://causalml.readthedocs.io/en/latest/quickstart.html
https://causalml.readthedocs.io/en/latest/examples/uplift_tree_visualization.html
https://causalml.readthedocs.io/en/latest/examples/validation_with_tmle.html
https://causalml.readthedocs.io/en/latest/examples/uplift_trees_with_synthetic_data.html
https://causalml.readthedocs.io/en/latest/examples/meta_learners_with_synthetic_data.html
https://github.com/uber/causalml/tree/master/docs/examples 
https://causalml.readthedocs.io/en/latest/interpretation.html#interpretable-causal-ml

Topic Modeling

https://www.tidytextmining.com/topicmodeling
http://freerangestats.info/blog/2017/01/05/topic-model-cv
https://knowledger.rbind.io/post/topic-modeling-using-r/

Power Analysis

https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html
https://www.evanmiller.org/ab-testing/sample-size.html

https://ekstroem.github.io/MESS/reference/power_prop_test.html 

https://machinelearningmastery.com/statistical-power-and-power-analysis-in-python/

https://www.statmethods.net/stats/power.html

https://med.und.edu/research/daccota/_files/pdfs/berdc_resource_pdfs/sample_size_r_module.pdf

https://campus.datacamp.com/courses/practicing-statistics-interview-questions-in-python/statistical-experiments-and-significance-testing?ex=9

https://datastud.dev/posts/ab-testing

https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportion_effectsize.html

https://jpktd.blogspot.com/2013/03/statistical-power-in-statsmodels.html

https://stackoverflow.com/questions/47299824/how-to-calculate-statistical-power-function-vs-sample-size-in-python

https://www.statsmodels.org/stable/generated/statsmodels.stats.power.NormalIndPower.solve_power.html

https://stat.ethz.ch/R-manual/R-patched/library/stats/html/power.prop.test.html

https://stats.stackexchange.com/questions/108226/r-power-prop-test-prop-test-and-unequal-sample-sizes-in-a-b-tests

https://rstudio-pubs-static.s3.amazonaws.com/223385_834484c22e2f41af9f515c8aa0c114d8.html

https://www.reddit.com/r/statistics/comments/9ev0th/help_with_proportion_test_with_unequal_sample_size/


 Stats Misc

https://bookdown.org/gabriel_butler/ECON41Labs/tutorial-4-the-binomial-distribution.html

https://cran.r-project.org/web/packages/infer/vignettes/t_test.html

https://uc-r.github.io/t_test

https://www.datanovia.com/en/lessons/t-test-in-r/

https://rpkgs.datanovia.com/rstatix/
https://rpkgs.datanovia.com/rstatix/reference/index.html

https://www.itl.nist.gov/div898/handbook/prc/section2/prc221.htm#:~:text=Tests%20of%20hypotheses%20that%20can,on%20the%20question%20at%20hand.


Python Notes

Ctrl+Alt+p : Create a cell above the current cell.
Ctrl+Alt+n : Create a cell below the current cell.
https://www.linkedin.com/pulse/databricks-useful-notebook-shortcuts-rajeev-kumar#:~:text=Ctrl%2BEnter%20%3A%20Run%20the%20current,cell%20below%20the%20current%20cell.


# modules = dir()
# for i in modules: 
#     print(i) 


  print("exposed_retention: %s" % (exposed_retention))
  print("control_retention: %s" % (control_retention)) 

print('\n the t test \n')
print("t statistic: %s" % (t_test.statistic)) 
print("pvalue:      %s" % (t_test.pvalue)) 
print('\n the prop test \n')
print(prop_test)   
 

# sd = math.sqrt(baseline_rate * (1 - baseline_rate) / population) 

data = {'t statistic': [t_test.statistic],
        'pvalue': [t_test.pvalue]}
 
# Create DataFrame
df = pd.DataFrame(data)
# df 

data = {'t statistic': ['-0.61'],
        'pvalue': ['0.851']}
df_n = pd.DataFrame(data)  

df = df.append(df_n, ignore_index=True)
df 

  # t_test = ttest_ind(a = control_sample, b = exposed_sample, equal_var = True).confidence_interval(confidence_level=0.95)
  # t_test_CI = t_test.confidence_interval(confidence_level=0.95)
  # t_test_output = {'t statistic': [t_test.statistic],
  #                   'pvalue':     [t_test.pvalue]}  
  # t_test_output = pd.DataFrame(t_test_output)


res = pg.ttest([12,13,14], [21,23,34], paired=False)
CIs  = res['CI95%'][0] 
low_CI  = CIs[0] 
high_CI = CIs[1]
t_stat  = float(res['T']) 
p_val   = float(res['p-val']) 

t_test_output = {'t statistic': [t_stat],
                'pvalue':       [p_val],
                'low_CI':       [low_CI],
                'high_CI':       [high_CI]}  
t_test_output = pd.DataFrame(t_test_output)  

print(t_test_output)
res 

def extract_t_test(t_res): 

    CIs  = t_res['CI95%'][0] 
    low_CI  = CIs[0] 
    high_CI = CIs[1]
    t_stat  = float(t_res['T']) 
    p_val   = float(t_res['p-val']) 

    t_test_output = {'t statistic': [t_stat],
                    'pvalue':       [p_val],
                    'low_CI':       [low_CI],
                    'high_CI':       [high_CI]}  
    t_test_output = pd.DataFrame(t_test_output)  
    t_test_output

extract_t_test(res)
t_test_output


control_sample = binomial(1, 0.5, size = control_n) 
exposed_sample = binomial(1, 0.62, size = exposed_n) 

exp = pd.DataFrame(exposed_sample) 
exp = exp.rename(columns={ exp.columns[0]: 'values'}) 

print(int(len(exp))) 
print(int(exp.query('values == 1').groupby(['values']).size())) 
int(exp.query('values == 0').groupby(['values']).size()) 


# short_term_params = pd.DataFrame({'baseline_rate': baseline_rate, 
#                                   'mde':           mde, 
#                                   'population':    population,
#                                   'control_ratio': control_ratio}) 

short_term_params = pd.DataFrame({'baseline_rate': baseline_rate, 
                                  'mde':           mde, 
                                  'population':    population,
                                  'control_ratio': control_ratio}, index=[0]) 



# long_term_params = pd.DataFrame({'baseline_rate': baseline_rate, 
#                                   'mde':           mde, 
#                                   'population':    population,
#                                   'control_ratio': control_ratio}) 


baseline_rate = [55, 60, 65]
mde = [0.02, 0.03, 0.04]  
population = [175000, 200000, 225000]
control_ratio = [5.66, 9, 19] 

# for w in baseline_rate: 
#     for x in mde: 
#         for y in population: 
#             for z in control_ratio:               
#                 print("baseline_rate: %s" % (w)) 
#                 print("mde: %s" % (x)) 
#                 print("population: %s" % (y)) 
#                 print("control_ratio: %s" % (z)) 
#                 print("\n")  


# sim_results.loc[:, ['control_ratio']].head(100)

# CHECK
vars = ['test', 'baseline_rate', 'mde', 'population', 'control_ratio']
check = pd.DataFrame((sim_results
                    .groupby(vars)
                    .size()))
print(check.to_string())        


(pn.ggplot(new_subscribers_sim_results) + 
    pn.aes(x = 'test', y = 'low_CI', color = "factor(test)") + 
    pn.facet_grid('baseline_rate + mde ~ population + control_ratio', scales='free') + 
    pn.geom_boxplot(color = 'black') +
    pn.geom_jitter(alpha = 0.2) + 
    pn.scale_y_continuous(labels=percent_format()) +
    pn.labs(title = 'Confidence Intervals by Test Type',
            subtitle = 'Sim Confidence Intervals', 
            caption = 'For 10K Simualted') + 
    pn.theme(figure_size=(16, 8))) 


    # if 'sim_results' in locals():
    #     del(sim_results) 


# if 't_test_results' in locals():
#   del(t_test_results) 
# if 'prop_test_results' in locals():
#   del(prop_test_results)   


 R Notes

# rnorm(5, mean=61, sd=3) 
seq(from=60,to=63,by=0.2)

rnorm(1, mean=61, sd=3) 
# x <- seq(from=60,to=63,by=0.2)
# length(x)


power.prop.test(n = c(192000,10100),
                p1 = 0.615, 
                p2 = 0.62,
                sig.level = 0.05, 
                alternative = "one.sided") 

library(Hmisc)
bsamsize(.01, .1, power=.9, frac=1/3)

require(devtools)
install_version(
  package = "Hmisc",
  repos   = "http://cran.us.r-project.org")

library(devtools)
install_version(
  package = "rstatix",
  repos   = "http://cran.us.r-project.org")



prop_test_results_ <- prop.test(x = c(exposed_retention_rate * exposed_n, 
                                     control_retention_rate * control_n),
                               n = c(exposed_n, control_n))
print(prop_test_results_) 
tidy(prop_test_results_)


t.test(1:10, y = 7:20) #, alternative = "greater")

t.test(1:12, 7:20, , alternative = "greater")
x_ = rbinom(n = 190000, size = 1, prob = exposed_retention_rate)
y_ = rbinom(n = 10000, size = 1, prob = control_retention_rate)

print(t.test(x_, y_, alternative = "greater"))

tidy(t.test(x_, y_, alternative = "greater"))


t.test(7:20, 1:10, alternative = "greater") 


sem <- function(x, na.rm = FALSE) {
  out <-sd(x, na.rm = na.rm)/sqrt(length(x))
  return(out)
}





def sim(baseline_rate, mde, population, control_ratio): 

    for i in range(1,1001): 

        control_n = math.ceil(population / control_ratio) 
        exposed_n = population - control_n 

        control_retention = math.ceil(control_n * (baseline_rate + mde))  
        exposed_retention = math.ceil(exposed_n * baseline_rate)
        
        control_sample = binomial(1, (baseline_rate + mde), size = control_n) 
        exposed_sample = binomial(1, baseline_rate, size = exposed_n) 

        t_test = pg.ttest(control_sample, exposed_sample, paired=False, alternative='greater') 
        t_test_output = extract_t_test(t_test) 

        control_sample_df = pd.DataFrame(control_sample)
        control_sample_df = control_sample_df.rename(columns={control_sample_df.columns[0]: 'values'}) 

        exposed_sample_df = pd.DataFrame(exposed_sample)
        exposed_sample_df = pd.DataFrame(exposed_sample).rename(columns={ exposed_sample_df.columns[0]: 'values'}) 

        prop_test = test_proportions_2indep(count1 = int(control_sample_df.query('values == 1').groupby(['values']).size()), 
                                            nobs1  = int(len(control_sample_df)),
                                            count2 = int(exposed_sample_df.query('values == 1').groupby(['values']).size()),
                                            nobs2  = int(len(exposed_sample_df)),
                                            alternative = 'larger')

        prop_test_ci = confint_proportions_2indep(count1 = int(control_sample_df.query('values == 1').groupby(['values']).size()), 
                                                nobs1  = int(len(control_sample_df)),
                                                count2 = int(exposed_sample_df.query('values == 1').groupby(['values']).size()),
                                                nobs2  = int(len(exposed_sample_df)))  

        prop_test_output = {'t statistic': [prop_test.statistic],
                            'pvalue':      [prop_test.pvalue],
                            'low_CI':      [prop_test_ci[0]],
                            'high_CI':     float('inf')}  # [prop_test_ci[1]]
        prop_test_output = pd.DataFrame(prop_test_output)  

        if 't_test_results' not in locals(): # Note: using the same check for both to be more compact; could use an and.. but seems fine 
            t_test_results    = t_test_output
            prop_test_results = prop_test_output
        else:
            t_test_output.reset_index(drop=True, inplace=True)
            t_test_results = pd.concat([t_test_results, t_test_output], ignore_index=True, axis=0)

            prop_test_results.reset_index(drop=True, inplace=True) 
            prop_test_results = pd.concat([prop_test_results, prop_test_output], ignore_index=True, axis=0)   

    return t_test_results, prop_test_results







